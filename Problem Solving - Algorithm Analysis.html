<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Анализ алгоритмов</title>
  <style>
   .colortext {
     color: red; /* Красный цвет выделения */
   }
  </style>
 </head>
 <body>

<h1>Анализ алгоритмов</h1>

<h2>Цели</h2>
<ul>
	<li>Понять, почему так важен анализ алгоритмов.</li>
	<li>Быть готовыми использовать нотацию "большого О" для описания времени выполнения.</li>
	<li>Понять "большое О" времени выполнения наиболее распространённых операций над списками и словарями в Python.</li>
	<li>Понять, как реализация данных в Python влияет на анализ алгоритмов.</li>
	<li>Понять, как находить критерии для простых программ на Python.</li>
</ul>

<h2>Что такое "анализ алгоритмов"?</h2>
<p>Студенты-первокурсники ИТ-специальностей очень часто сравнивают свои программы с другими. Вы могли замечать, что быть похожими друг на друга - общее свойство многих компьютерных программ, особенно простых. В связи с этим возникает интересный вопрос: если две программы решают одну и ту же задачу, но выглядят по разному, как понять, что одна из них лучше?</p>

<p>Чтобы на него ответить, нам нужно вспомнить о важном различии между собственно программой и алгоритмом, который она воплощает. Как мы говорили в главе 1, алгоритм - это универсальная пошаговая инструкция по решению задачи. Это метод для решения любого частного случая проблемы, такой, что при заданных входных значениях алгоритм выдаёт требуемый результат. С другой стороны, программа - это то, как алгоритм переложен на некий язык программирования. Может быть множество программ, реализующих один и тот же алгоритм в зависимости от программиста и языка, который он использует.</p>

<p>Для дальнейшего исследования этого различия рассмотрим функцию в <i>ActiveCode 1</i>. Она решает всем знакомую задачу вычисления суммы первых <i>n</i> целых чисел. Алгоритм использует идею переменной-аккумулятора, которая инициализируется нулём. В процессе решения перебираются <i>n</i> чисел, каждое из которых прибавляется к аккумулятору.</p>

<p align="center"><b>Active Code: 1</b> Суммирование первых n целых чисел</p>

<p>А сейчас посмотрите на функцию в <i>ActiveCode 2</i>. На первый взгляд она может показаться странной, но при более близком рассмотрении вы увидите, что она делает в точности то же самое, что и предыдущая. Причина, по которой это не очевидно, в плохом качестве кода. Мы не используем понятные имена для идетификаторов, чтобы повысить читабельность, и мы делаем избыточное присваивание на шаге аккумуляции, что совершенно не является необходимым.</p>

<p align="center"><b>Active Code: 2</b> Другое суммирование первых n целых чисел</p>

<p>В ранее озвученном вопросе мы спрашивали: как понять, что одна функция лучше другой? Ответ будет зависеть от выбранных критериев. Функция <code>sumOf</code> естественно лучше, чем <code>foo</code>, если вы беспокоитесь о читабельности. Фактически, вы, возможно, видели множество подобных примеров в ваших вводных курсах по программированию, поскольку одной из их целей является желание помочь вам научиться писать программы, которые легко читать и понимать. Однако, в этом курсе мы заинтересованы в том, чтобы охарактеризовывать алгоритм сам по себе. (Мы также надеемся, что вы продолжите бороться за читаемый и хорошо понимаемый код.)</p>

<p>Анализ алгоритмов основывается на сравнении алгортмов по затрачиваемому каждым из них объёму вычислительных ресурсов. Мы хотим быть готовыми взять два алгоритма и сказать, что один из них лучше другого, потому что он более эффективно использует имеющиеся ресурсы или, возможно, ему их просто меньше нужно. С этой точки зрения две функции выше выглядят очень похожими. Они обе используют один и тот же алгоритм для решения проблемы суммирования.</p>

<p>На данный момент становится важным поразмыслить над тем, что же мы подразумеваем под "вычислительными ресурсами". Существует два различных подхода к этому вопросу. Первый рассматривает объём пространства или памяти, требуемый алгоритму для решения задачи. Эта величина обычно зависит от конкретного варианта проблемы. Однако, часто встречаются алгоритмы, имеющие специфические требования к объёму, и в таких случаях нам надо очень аккуратно подходить к объяснению вариантов.</p>

<p>Альтернативой требований к пространству является анализ и сравнение алгоритмов по времени, которое им требуется для вычислений. Эту величину иногда называют "временем выполнения" алгоритма. Одним из способов измерить время выполнения функции <code>sumOfN</code> является проведение сравнительного анализа. Он подразумевает, что мы засечём реальное время, требуемое программе на вычисление результата. В Python мы можем проделать эту операцию, отметив время начала и время окончания работы программы относительно используемой нами системы. В модуле <code>time</code> есть функция <code>time</code>, которая возвращает текущее системное время в секундах, прошедшее с некоторого произвольного начального момента. Вызвав эту функцию дважды - в начале и в конце, - и затем посчитав разницу, мы получим точное количество секунд (дробное в большинстве случаев), затраченных на выполнение.</p>

<b>Листинг 1</b>
{% highlight Python %}
import time

def sumOfN2(n):
   start = time.time()

   theSum = 0
   for i in range(1,n+1):
      theSum = theSum + i

   end = time.time()

   return theSum,end-start
{% endhighlight %}

<p><i>листинг 1</i> демонстрирует оригинальную функцию <code>sumOfN</code> с вызовами времени, встроенными до и после суммирования. Она возвращает кортеж, состоящий из результата и количества затраченного на вычисления времени (в секундах). Если мы выполним пять вызовов функции, в каждос из которых будет вычисляться сумма первых 10000 целых чисел, то мы получим следующее:</p>

{% highlight Python %}
>>>for i in range(5):
       print("Sum is %d required %10.7f seconds"%sumOfN(10000))
Sum is 50005000 required  0.0018950 seconds
Sum is 50005000 required  0.0018620 seconds
Sum is 50005000 required  0.0019171 seconds
Sum is 50005000 required  0.0019162 seconds
Sum is 50005000 required  0.0019360 seconds
{% endhighlight %}

<p>Мы выяснили, что результат хорошо повторяем и что на выполнение кода затрачивается примерно 0,0019 секунд. Что, если теперь мы сложим первые 100000 целых?</p>

{% highlight Python %}
>>>for i in range(5):
       print("Sum is %d required %10.7f seconds"%sumOfN(100000))
Sum is 5000050000 required  0.0199420 seconds
Sum is 5000050000 required  0.0180972 seconds
Sum is 5000050000 required  0.0194821 seconds
Sum is 5000050000 required  0.0178988 seconds
Sum is 5000050000 required  0.0188949 seconds
>>>
{% endhighlight %}

<p>Снова времена, необходимые для каждого запуска, лежат близко друг к другу, но становятся длиннее - примерно в десять раз. Для <code>n</code>, равной 1000000 мы получим:</p>

{% highlight Python %}
>>>for i in range(5):
       print("Sum is %d required %10.7f seconds"%sumOfN(1000000))
Sum is 500000500000 required  0.1948988 seconds
Sum is 500000500000 required  0.1850290 seconds
Sum is 500000500000 required  0.1809771 seconds
Sum is 500000500000 required  0.1729250 seconds
Sum is 500000500000 required  0.1646299 seconds
>>>
{% endhighlight %}

<p>Среднее значение вновь выросло примерно в десять раз, по сравнению с предыдущим.</p>

<p>А теперь рассмотрим <i>ActiveCode 3</i>, демонстрирующий другой способ решения задачи суммирования. Эта функция, <code>sumOfN3</code> использует преимущество замкнутой формулы  ∑ni=1i=(n)(n+1)2 для вычисления суммы первых <code>n</code> целых без выполнения итераций.</p>

<p align="center"><b>Active Code: 3</b> Суммирование без итераций</p>

<p>Если мы проведём аналогичные контрольные замеры для <code>sumOfN3</code>, используя пять различных значений для <code>n</code> (10 000, 100 000, 1 000 000, 10 000 000 и 100 000 000), то получим следующие результаты:</p>

{% highlight Python %}
Sum is 50005000 required 0.00000095 seconds
Sum is 5000050000 required 0.00000191 seconds
Sum is 500000500000 required 0.00000095 seconds
Sum is 50000005000000 required 0.00000095 seconds
Sum is 5000000050000000 required 0.00000119 seconds
{% endhighlight %}

<p>Есть два важных момента, связанных с этими выходными данными, на которые стоит обратить внимание. Первый - затраченное время намного меньше, чем в любом из предыдущих примеров. И второй - все временные величины очень близки друг к другу, вне зависимости от значения <code>n</code>. Похоже, что <code>sumOfN3</code> абсолютно всё равно, сколько чисел ей требуется сложить.</p>

<p>Но что этот тест говорит нам в действительности? Интуитивно мы догадываемся, что итеративное решение будет выполнять больше работы из-за повторения некоего набора программных шагов. Это, скорее всего, причина, по которой оно занимает больше времени. Так же похоже, что время, требуемое итеративному решению, возрастает при увеличении значения <code>n</code>. Тут, однако, возникает проблема. Если мы запустим одну и ту же функцию на разных компьютерах или используем различные языки программирования, то вполне вероятно, что получим разные результаты. Вычисление <code>sumOfN3</code> займёт тем больше времени, чем старше компьютер.</p>

<p>Нам нужен более хороший способ охарактеризовывать алгоритмы относительно времени выполнения. Тестовая методика вычисляет действительное время выполнения. Она не предоставляет нам действительного полезного результата измерений, поскольку он зависит от конкретной машины, программы, времени дня, компилятора и языка программирования. Вместо этого мы хотели бы иметь характеристику, не зависящую от программы или компьютера. Такое измерение было бы полезным для оценки алгоритма самого по себе и его можно было бы использовать для сравнения алгоритмов в различных реалиазациях.</p>

<h3>Нотация "большое О"</h3>
<p>При попытке охарактеризовать эффективность алгоритма в терминах времени выполнения независимо от конкретной программы или компьютера, очень важно оценить количество операций или шагов, которые потребуются алгоритму. Если каждый из этих шагов принять за базовую единицу вычисления, то время выполнения алгоритма может быть выражено, как количество шагов, требуемых для решения задачи. Принятие решение о том, что же является таким базовым блоком вычисления, может быть сложной задачей, зависящей от того, как алгоритм реализован.</p>

<p>Хорошей базовой единицей вычисления для сравнения суммирующих алгоритмов, показанных ранее, может служить количество операций присваивания, используемых при подсчёте суммы. В функции <code>sumOfN</code> есть только одно такое присваивание (<b><i>theSum=0</i></b>) плюс значение <i>n</i> (сколько раз мы вычисляем <b><i>theSum=theSum+i</i></b>). Мы можем обозначить эту величину (назовём её T), где <b><i>T(n)=1+n</i></b>. Параметр <i>n</i> часто называют "размером задания", так что мы можем прочитать это как "T(n) - это время, необходимое для решения задачи, размером n, за 1+n шагов."</p>

<p>В представленных выше функциях суммирования для обозначения размера задачи имеет смысл использовать количество слагаемых. Так мы сможем сказать, что суммирование первых 100 000 целых - задание большее, чем суммирование первой тысячи. Поэтому выглядит разумным положение, что время, требуемое на решение большего случая, будет больше, чем для меньшего случая. Таким образом, наша цель - показать, как время работы алгоритма изменяется в зависимости от размера задачи.</p>

<p>Учёные-информатики при использовании такой техники анализа предпочитают идти на один шаг дальше. Выходит так, что точное количество опраций не так важно, как определение наиболее доминирующей части функции <b><i>T(n)</i></b>. Другими словами, когда задание становится больше, некая часть функции <b><i>T(n)</i></b>, как правило, перекрывает всё остальное. Эта доминирующая часть в итоге и используется при сравнении. Функция <b>порядка величины</b> описывает ту часть <b><i>T(n)</i></b>, которая сильнее возрастает при росте <i>n</i>. Порядок величины часто называют <b>нотацией "большое О"</b> (от <i>order</i> - порядок) и записывают как <b><i>O(f(n))</i></b>. Он предоставляет целесообразное приближение к действительному числу шагов в вычислении. Функция <b><i>f(n)</i></b> является простым представлением доминирующей части оригинальной <b><i>T(n)</i></b>.</p>

<p>В примере выше <b><i>T(n)=1+n</i></b>. Чем больше становится <i>n</i>, тем менее значимой для конечного результата становится константа 1. При поиске приближения для <b><i>T(n)</i></b> мы можем отбросить 1 и просто сказать, что временем выпонения является <b><i>O(n)</i></b>. Важно отметить, что 1 безусловно важна для <b><i>T(n)</i></b>. Однако, при росте <i>n</i> наше приближение останется столь же точным и без неё.</p>

<p>Ещё один пример: предположим, что для некоего алгоритма точное число шагов <b><i>T(n)=5n2+27n+1005</i></b>. При малых <i>n</i> (скажем, 1 или 2) константа 1005 выглядит доминирующей частью функции. Однако, с ростом <i>n</i>, превалирующим становится слагаемое <b><i>n<sup>2</sup></i></b>. Фактически, когда <i>n</i> действительно велико, то два других слагаемых перестают играть хоть какую-нибудь значимую роль в определении конечного результата. Ещё раз, аппроксимируя <b><i>T(n)</i></b> с ростом <i>n</i>, мы можем игнорировать другие слагаемые и сфокусироваться только на <b><i>5n<sup>2</sup></i></b>. Дополнительно, коэффициент <b>5</b> тоже становится неважным при увеличении <i>n</i>. Так что мы можем сказать, что функция <b><i>T(n)</i></b> имеет порядок величины <b><i>f(n)=n<sup>2</sup></i></b>, или просто <b><i>O(n<sup>2</sup>)</i></b></p>

<p>Хотя мы и не видим этого в примере с суммированием, иногда производительность алгоритма зависит от точных значений данных больше, чем от размера задачи. Для алгоритмов такого рода нам нужно характеризовать их эффективность с точки зрения <b>наилучшего, наихудшего</b> или <b>усреднённого случая</b>. Производительность для худшего случая относится к определённому набору данных, на котором алгоритм выполняется особенно плохо. В то время как различные наборы данных для точно такого же алгоритма могут иметь необычайно хорошую производительность, в большинстве случаев алгоритм имеет производительность где-то по середине между этими двумя экстремумами (усреднённый случай). Учёным-информатикам важно понимать эти различия, чтобы на впасть в заблуждение при рассмотрении одного конкретного случая.</p>

<p>Некоторое количество очень распространённых функций порядка величины будет попадаться вам вновь и вновь в процессе изучения алгоритмов. Все они представлены в <i>таблице 1</i>. Для того, чтобы увидеть, какая из них является доминирующей частью любое функции <b><i>T(n)</i></b>, мудолжны видеть, как они соотносятся друг с другом при возрастании <i>n</i></p>.

<table border="1">
  <caption><b>Таблица 1: Наиболее рапространённые функции для "большого О"</b></caption>
  <tr>
    <td><b>f(n)</b></td><td><b>Название</b></td>
  </tr>
  <tr>
    <td>1</td><td>Константная</td>
  </tr>
  <tr>
    <td>log <i>n</i></td><td>Логарифмическая</td>
  </tr>
  <tr>
    <td><i>n</i></td><td>Линейная</td>
  </tr>
  <tr>
    <td><i>n</i> log <i>n</i></td><td>Линейно-логарифмическая</td>
  </tr>
  <tr>
    <td><i>n<sup>2</sup></i></td><td>Квадратичная</td>
  </tr>
  <tr>
    <td><i>n<sup>3</sup></i></td><td>Кубичесткая</td>
  </tr>
  <tr>
    <td><i>2<sup>n</sup></i></td><td>Экспоненциальная</td>
  </tr>
</table>

<p>На <i>рисунке 1</i> показаны графики распространённых функций из <i>таблицы 1</i>. Обратите внимание, что при малых <i>n</i> функции нелегко отличить друг от друга и тяжело сказать, какая из них доминирует. Однако, как только <i>n</i> вырастает, появляется определённая зависимость, и легко увидеть, как они соотносятся друг с другом.</p>

<p align="center"><img src="http://interactivepython.org/runestone/static/pythonds/_images/newplot.png"></p>
<p align="center">Рисунок 1: Графики распространённых функций "большое О"</p>

<p>В качестве заключительного примера предположим, что у нас есть фрагмент кода на Python, показанный в <i>Листинге 2</i>. Несмотря на то, что на самом деле эта программа ничего не делает, полезно будет посмотреть, как мы можем взять существующий код и проанализировать его производительность.</p>

<b>Листинг 2</b>
{% highlight Python %} 
a=5
b=6
c=10
for i in range(n):
   for j in range(n):
      x = i * i
      y = j * j
      z = i * j
for k in range(n):
   w = a*k + 45
   v = b*b
d = 33
{% endhighlight %}

<p>Число операций присваивания представляет собой сумму из четырёх слагаемых. Первое - константа 3, представляющая три присваивания в начале фрагмента. Второе - <b><i>3n<sup>2</sup></i></b>, поскольку три присваивания выполняются <b><i>n<sup>2</sup></i></b> раз внутри вложенной итерации. Третье - <b><i>2n</i></b>, два присваивания, повторяющиеся <i>n</i> раз. Наконец, четвёртое слагаемое - константа 1, представляющая последний оператор присваивания. Всё вместе это даёт <b><i>T(n)=3+3n<sup>2</sup>+2n+1=3n<sup>2</sup>+2n+4</i></b>. Глядя на степени, мы легко можем заметить, что слагаемое <b><i>n<sup>2</sup></i></b> будет доминантой, и следовательно, этот фрагмент кода является <b><i>O(n<sup>2</sup>)</i></b>. Обратите внимание, что прочие слагаемые (так же, как и коэффициенты) можно проигнорировать при возрастании <i>n</i>.</p>

<p align="center"><img src="http://interactivepython.org/runestone/static/pythonds/_images/newplot2.png"></p>
<p align="center">Рисунок 2: Сравнение <b><i>T(n)</i></b> с распространёнными функциями "большого О"</p>

<p>На рисунке 2 показаны графики нескольких распространённых функций "большое О" в сравнении с обсуждаемой выше функцией <b><i>T(n)</i></b>. Обратите внимание, что в изначально <b><i>T(n)</i></b> больше, чем кубическая функция, но с ростом <i>n</i> последняя быстро берёт верх над <b><i>T(n)</i></b>. Так же легко увидеть, что <b><i>T(n)</i></b> с ростом <b><i>n</i></b> следует квадратичной функции.</p>

<b>Самопроверка</b>
<p>Напишите на Python две функции для поиска минимального значения в списке. Первая из них должна сравнивать каждое число со всеми другими значениями в списке. <b><i>O(n<sup>2</sup>)</i></b>. Вторая функция должна быть линейной с <b><i>O(n)</i></b></p>

<h3>Пример с определением анаграммы</h3>
<p>Хорошим примером для демонстрации алгоритмов с разным порядком величины является классическая задача для строк - определения анаграммы. Одна строка является анаграммой другой, если вторая получается простой перестановкой букв первой. Например, <code>'heart'</code> и <code>'earth'</code> - это анаграммы. Как и строки <code>'python'</code> и <code>'typhon'</code>. Для простоты будем полагать, что обе заданные строки одной длины и составлены из набора символов в 26 букв в нижнем регистре. Нашел целью будет написать булеву функцию, принимающую две строки и возвращающую ответ - являются ли они анаграммами?</p>

<h4>Решение 1: Метки</h4>
<p>Наше первое решение задачи про анаграмму будет проверять, входит ли каждый из символов первой строки во вторую. Если все символы будут "отмечены", то строки являются анаграммами. "Пометка" символа будет выполняться с помощью замены его на специальное значение Python <code>None</code>. Однако, поскольку строки в Python иммутабельны, первым шагом обработки будет конвертирование второй строки в список. Каждый символ из первой строки может быть сверен с элементами списка и, если будет найден, отмечен оговоренной заменой. <i>ActiveCode 4</i> демонстрирует эту функцию.</p>

<p align="center"><b>Active Code: 4</b> Метки</p>

<p>При анализе алоритма нам стоит отметить, что каждый из <i>n</i> символов в <code>s1</code> вызовет цикл по <i>n</i> символам списка, полученного из <code>s2</code>. Каждая из <i>n</i> позиций списка будет посещена единожды, чтобы проверить её на соответствие <code>s1</code>. Количество таких посещений будет выражено через сумму целых чисел от 1 до <i>n</i>. Ранее мы уже говорили, что это может быть записано как</p>

<p>∑i=1ni=n(n+1)2=12n2+12n</p>

<p>С увеличением <b><i>n</i></b> слагаемое <b><i>n<sup>2</sup></i></b> начнёт доминировать, так что <b><i>n</i></b> и <b><i>1/2</i></b> можно проигнорировать. Таким образом, решение является <b><i>O(n<sup>2</sup>)</i></b>.</p>

<h4>Решение 2: Сортируй и сравнивай</h4>

<p>Следующие решение задачи про анаграммы будет использовать тот факт, что даже если <code>s1</code> и <code>s2</code> различны, они будут анаграммами только если состоят из одинаковых символов. Следовательно, если мы отсортируем каждую строку в алфавитном порядке от <i>a</i> до <i>z</i>, то в итоге получим одинаковые строки (если, конечно, <code>s1</code> и <code>s2</code> - анаграммы). Это решение показано в <i>ActiveCode 5</i>. Опять же, в Python мы можем использовать встроенный метод <code>sort</code>, для списков, полученных в начале функции конвертацией каждой строки.</p>

<p align="center"><b>Active Code: 5</b> Сортируй и сравнивай</p>

<p>В первый момент вы можете подумать, что этот алгоритм имеет <b><i>O(n)</i></b>, поскольку у него есть всего одна простая итерация для сравнения <i>n</i> символов после сортировки. Однако, два вызова Python-метода <code>sort</code> не проходят даром. Как мы увидим в следующих главах, сортировка обычно имеет <b><i>O(n<sup>2</sup>)</i></b> или <b><i>O(n</i> log <i>n)</i></b>, так что эта операция доминирует над циклом. В итоге алгоритм будет иметь тот же порядок операций, что и сортировочные вычисления.</p>

<h4>Решение 3: Полный перебор</h4>

<p>Техника <b>полного перебора</b> для решения задач обычно используется, когда все другие возможности уже исчерпаны. Для задачи определения анаграммы мы можем просто сгенерировать список всех возможных строк из символов <code>s1</code> и посмотреть, входит ли в него <code>s2</code>. Но в данном подходе есть одна закавыка: при генерации всех возможных строк из <code>s1</code> есть <i>n</i> возможных первых символов, <b><i>n</i> - 1</b> возможных вторых символов и так далее. Отсюда общее количество строк-кандидатов будет <b><i>n</i>*(<i>n</i>−1)*(<i>n</i>−2)*...*3*2*1</b>, что есть <b><i>n</i>!</b>. Несмотря на то, что некоторые строки будут дублироваться, программа об этом заранее знать не будет, поэтому всё равно сгенерирует <b><i>n</i>!</b> различных строк.</p>

<p>Решение <b><i>n</i>!</b> с увеличением <i>n</i>возрастает быстрее, чем даже <b>2<sup><i>n</i></sup></b>. Фактически, при длине <code>s1</code> в 20 символов мы получим <b>20!=2 432 902 008 176 640 000</b> возможных строк-кандидатов. Если мы будем обрабатывать одну вероятность каждую секунду, то на весь список уйдёт 77 146 816 596 лет. Похоже, это совсем не хорошее решение.</p>

<h4>Решение 4: Подсчитывай и сравнивай</h4>

<p>Наше последнее решения задачи про анаграммы воспользуется преимуществом того факта, что любые две анаграммы имеют одинаковое количество букв <i>a</i>, <i>b</i> и так далее. Для того, чтобы решить, являются ли строки анаграммами, мы сначала подсчитаем, сколько раз в них встречается каждый символ. Поскольку возможных букв 26, то мы можем использовать список из 26 счётчиков - по одному на каждый символ. Каждый раз, когда мы видим кокретную букву, мы увеличиваем соответствующий ей счётчик на единицу. В итоге, если оба списка счётчиков идетичны, то строки - анаграммы. Это решение показано в <i>ActiveCode 6</i>.</p>

<p align="center"><b>Active Code: 6</b> Подсчитывай и сравнивай</p>

<p>Решение вновь имеет некоторое количество циклов. Однако, в отличии от первого варианта, ни один из них не является вложенным. Два первых цикла, используемые для подсчёта символов, базируются на <i>n</i>. Третий цикл - сравнение двух списков счётчиков - всегда состоит из 26 итераций (поскольку строки состоят из 26 возможных элементов). Складывая всё вместе, получим <b>T(<i>n</i>)=2<i>n</i>+26</b> шагов, что является <b>O(<i>n</i>)</b>. Мы нашли алгоритм с линейным порядком величины для решения нашей задачи.</p>

<p>До того, как закончить с этим примером, стоит сказать несколько слов о пространственных требованиях. Хотя последнее решение и работает за линейное время, оно достигает этого путём использования дополнительных хранилищ для двух списков счётчиков. Другими словами, этот алгоритм приносит в жертву пространство, чтобы выиграть время.</p>

<p>Это очень распространённый случай. Очень часто вам придётся делать выбор между временем и пространством. В данном случае объём места был не существенен. Однако, если основополагающий алфавит имеет миллионы символов, то это вызовет больше беспокойства. Как у учёных-информатиков, при выборе алгоритма только от вас будет зависеть определение наилучшего использования вычислительных ресурсов, выделенных под конкретную задачу.</p>

<b>Самопроверка</b>
<p>Q-1: Каково "большое О" времени выполнения для следующего фрагмента кода?</p>
<p>Q-2: Каково "большое О" времени выполнения для следующего фрагмента кода?</p>
<p>Q-3: Каково "большое О" времени выполнения для следующего фрагмента кода?</p>

<h1>Производительность структур данных в Python</h1>

<p>Теперь, когда у вас есть общее представление о том, что же такое нотация "большое О" и в чём заключаются различия между разными функциями, наша цель в этом разделе - рассказать вам о производительности операций над списками и словарями в Python. Мы проведём несколько временнЫх экспериментов, чтобы продемонстрировать затраты и выгоды при использовании конкретных операций каждой из озвученных структур данных. Понимать эффективность этих структур - очень важно для вас, потому что они являются строительными блоками, которые мы будем использовать при реализации других структур данных на протяжении оставшихся глав этой книги. В этом разделе мы не планируем объяснять, почему производительность такая, какая она есть. Позднее вы сами увидите возможные реализации списков и словарей, и как производительность зависит от реализации.</p>

<h2>Списки</h2>

<p>Разработчики Python имели обширный выбор, когда реализовывали списки как структуру данных. Каждое их решение оказывает влияние на скорость выполения операций со списками. Чтобы помочь себе принимать верные решения, они смотрели на то, для чего пользователи используют списки чаще всего, и они оптимизировали реализацию списков таким образом, чтобы наиболее распространённые операции совершались очень быстро. Конечно, они так же старались сделать быстрыми и менее используемые операции, но при поиске компромиссов производительность менее распространённых операций приносилась в жертву в пользу более распространённых операций.</p>

<p>Двумя наиболее распространёнными операциями для списков являются индексация и присваивание на заданную позицию. Обе они занимают равное количество времени, вне зависимости от того, насколько велик список. Когда операции не зависят от размера списка (как названные выше), говорят, что они имеют <b><i>O</i>(1)</b>.</p>

<p>Другим часто встречающимся программистским заданием является увеличение списка. Существует два способа продлить список. Вы можете исользовать метод добавления или оператор конкатенации. Первый является <b><i>O</i>(1)</b>, но вот второй имеет <b><i>O(k)</i></b>, где <i>k</i> - размер списка, который будет присоединён. Эта информация полезна вам, потому что помогает сделать ваши программы более эффективными, выбирая правильный инструмент для работы.</p>

<p>Давайте рассмотрим четыре разных способа сгенерировать список из <code>n</code> чисел, начинающийся с нуля. Сначала мы попробуем цикл <code>for</code> и создадим список с помощью конкатенации. Затем используем для этого метод <code>append</code>. Далее попытаемся создать список, используя генераторы списков. И, наконец, используем для этого, возможно, самый очевидный способ - функцию <code>range</code>, обёрнутую в конструктор списка. <i>Листинг 3</i> показывает код для всех этих четырёх способов.</p>

<b>Листинг 3</b>
{% highlight Python %}
def test1():
    l = []
    for i in range(1000):
        l = l + [i]

def test2():
    l = []
    for i in range(1000):
        l.append(i)

def test3():
    l = [i for i in range(1000)]

def test4():
    l = list(range(1000))
{% endhighlight %}

<p>Чтобы получить время, требуемое для выполнения каждой функции, мы используем модуль Python <code>timeit</code>. Он разработан для того, чтобы разработчики на Python могли делать кроссплатформенные синхронные измерения, запуская функции в согласованной среде и используя механизмы синхронизации, максимально схожие между собой для разных операционных систем.</p>

<p>Чтобы использовать <code>timeit</code>, вам нужно создать объект <code>Timer</code>, чьими параметрами являются два положения на Python. Первый параметр - оператор Python, говорящий, что вам нужно время; второй - утверждение, что тест будет проводиться один раз. Модуль <code>timeit</code> будет несколько раз замерять время, необходимое для выполнения операции. По умолчанию он пытается запустить операцию один миллион раз. Когда это будет сделано, он вернёт время как число с плавающей запятой, представляющее собой общее количество секунд. Однако, поскольку он вычислял оператор миллион раз, то вы можете прочитать результат, как количество микросекунд, затраченныз на выполнение одного теста. Так же можно передать в <code>timeit</code> именованный параметр <code>number</code>, который позволит вам конкретизировать, сколько раз нужно запустить оператор. Следующий фрагмент показывает, как долго занимает запуск каждой тестовой функции тысячу раз.</p>

{% highlight Python %}
t1 = Timer("test1()", "from __main__ import test1")
print("concat ",t1.timeit(number=1000), "milliseconds")
t2 = Timer("test2()", "from __main__ import test2")
print("append ",t2.timeit(number=1000), "milliseconds")
t3 = Timer("test3()", "from __main__ import test3")
print("comprehension ",t3.timeit(number=1000), "milliseconds")
t4 = Timer("test4()", "from __main__ import test4")
print("list range ",t4.timeit(number=1000), "milliseconds")

concat  6.54352807999 milliseconds
append  0.306292057037 milliseconds
comprehension  0.147661924362 milliseconds
list range  0.0655000209808 milliseconds
{% endhighlight %}

<p>В эксперименте выше, операторами, для которых мы замеряли время, являются функции <code>test1()</code>, <code>test2()</code> и так далее. Опреатор начальной установки может показать вам очень необычным, так что давайте разберём детали. Возможно, вы хорошо знакомы с опреаторами <code>from</code> и <code>import</code>, но они обычно используются в начале файлов программ на Python. В нашем случае, оператор <code>from __main__ import test1</code> импортирует функцию <code>test1</code> из пространства имён <code>__main__</code> в пространство имён, в котором <code>timeit</code> ставит свой временнОй эксперимент. Он делает это потому, что хочет запускать тесты в среде, где отсутствуют бродячие переменные, которые вы могли создать и которые могут повлиять на производительность вашей функции непредвиденным образом.</p>

<p>Из эксперимента выше совершенно ясно, что операция <code>append</code> за 0.30 миллисекунд быстрее, чем конкатенация за 6.54 миллисекунды. Также мы видим время, требуемое для двх дополнительных методов создания списков: использования конструктора списка с вызовом <code>range</code> и генератора списков. Интересно, что последний в два раза быстрее, чем цикл <code>for</code> с операцией <code>append</code>.</p>

<p>Наше последнее наблюдение в этом маленьком эксперименте заключается в том, что все времена, которые вы видите выше, содержат некоторые издержки при фактическом вызове тестовой функции. Однако, мы можем предположить, что для всех четырёх случаев эта величина одинакова, так что мы по-прежнему имеем адекватное сравнение операций. Поэтому правильно говорить не "конкатенация занимает 6.54 миллисекунды", а "тестовая функция конкатенации выполняется 6.54 миллисекунд". В качестве упражнения, вы можете провести временнОй тест для пустой функции и вычесть его результат из чисел выше.</p>

<p>После того, как мы увидели, как конкретно может быть измерена производительность, вы можете посмотреть в <i>таблицу 2</i>, чтобы узнать эффективность в терминах "большого О" для основных операций над списками. После вдумчивого размышления над ней, вы можете заинтересоваться двумя разными временами для <code>pop</code>. Когда этот метод вызывается для конца списка, это занимает <b><i>O</i>(1)</b>. Но когда <code>pop</code> вызывают для первого или любого другого элемента из середины списка, он имеет <b><i>O(n)</i></b>. Причина кроется в том, как в Python выбрана реализация списков. Когда элемент берётся из начала списка, то все прочие элементы смещаются на одну позицию вперёд. Сейчас это может показаться вам глупым, но если вы посмотрите на <i>таблицу 2</i>, то увидите, что эта же реализация позволяет операции индексации иметь <b><i>O</i>(1)</b>. Это один из тех компромиссов, которые разработчики Python сочли разумными.</p>

<table border="1">
  <caption><b>Таблица 2: Эффективность операторов для списков в Python в терминах нотации "большое О"</b></caption>
  <tr>
    <td>Операция</td><td>Эффективность</td>
  </tr>
  <tr>
    <td>Индекс []</td><td>O(1)</td>
  </tr>
  <tr>
    <td>Присваивание по индексу</td><td>O(1)</td>
  </tr>
  <tr>
    <td>append</td><td>O(1)</td>
  </tr>
  <tr>
    <td>pop()</td><td>O(1)</td>
  </tr>
  <tr>
    <td>pop(i)</td><td>O(n)</td>
  </tr>
  <tr>
    <td>insert(i, item)</td><td>O(n)</td>
   </tr>
   <tr>
    <td>Оператор del</td><td>O(n)</td>
  </tr>
  <tr>
    <td>Итерирование</td><td>O(n)</td>
  </tr>
  <tr>
    <td>Вхождение (in)</td><td>O(n)</td>
  </tr>
  <tr>
    <td>Срез [x:y]</td><td>O(k)</td>
  </tr>
  <tr>
    <td>Удалить срез</td><td>O(n)</td>
  </tr>  
  <tr>
    <td>Задать срез</td><td>O(n + k)</td>
  </tr>  
  <tr>
    <td>Обратить</td><td>O(n)</td>
  </tr>
  <tr>
    <td>Конкатенация</td><td>O(k)</td>
  </tr>
  <tr>
    <td>Сортировка</td><td>O(n log n)</td>
  </tr>
  <tr>
    <td>Размножить</td><td>O(nk)</td>
  </tr>
</table>

<p>В качестве способа демонстрации этих различий в производительности, давайте проведём другой эксперимент с использованием модуля <code>timeit</code>. Нашей целью будет возможность проверки производительности операции <code>pop</code> на списке известного размера, когда программа выталкивает элемент из конца списка, и ещё раз - когда программа вталкивает элемент из начала списка. Мы также произведём замеры времени на списках разной длины. Что мы ожидаем увидеть, так это то, что временнАя зависимость у выталкивания из конца списка остаётся одинаковой при увеличении списка, в то время как выталкивание из начала списка будет расти вместе со списковой длиной.</p>

<p><i>Листинг 4</i> демонстрирует одну попытку замерить разницу между двумя использованиями <code>pop</code>. Как видно из первого примера, выталкивание с конца занимает 0.0003 миллисекунды, в то время как на выталкивание из начала требуется 4.82 миллисекунды. Для списка в два миллиона элементов коэффициент будет 16 000</p>

<p>Есть ещё несколько замечаний относительно <i>листинга 4</i>. Первое - это оператор <code>from __main__ import x</code>. Несмотря на то, что мы не определяли функцию, мы хотим иметь возможность использовать список-объект <code>x</code> в нашем тесте. Этот подход позволяет нам замерять время только для единственной <code>pop</code>-операции и получать для неё наиболее точное значение времени. Поскольку замеры повторяются тысячу раз, то также важно отметить, что список уменьшается в размерах на единицу за каждую итерацию. Но поскольку изначально в нём два миллиона элементов, то общий объём уменьшится примерно на 0.05%</p>

<b>Листинг 4</b>
{% highlight Python %}
popzero = timeit.Timer("x.pop(0)",
                       "from __main__ import x")
popend = timeit.Timer("x.pop()",
                      "from __main__ import x")

x = list(range(2000000))
popzero.timeit(number=1000)
4.8213560581207275

x = list(range(2000000))
popend.timeit(number=1000)
0.0003161430358886719
{% endhighlight %}

<p>Пока наш первый тест показывает, что <code>pop(0)</code> действительно медленнее <code>pop()</code>. Но он не подтверждает заявление, что <code>pop(0)</code> является <b><i>O(n)</i></b>, в то время как <code>pop()</code> - <b><i>O(1)</i></b>. Чтобы доказать это, нам нужно рассмотрет производительность обоих вызовов на диапазоне размеров списков. <i>Листинг 5</i> реализует этот тест.</p>

<b>Листинг 5</b>
<{% highlight Python %}>
popzero = Timer("x.pop(0)",
                "from __main__ import x")
popend = Timer("x.pop()",
               "from __main__ import x")
print("pop(0)   pop()")
for i in range(1000000,100000001,1000000):
    x = list(range(i))
    pt = popend.timeit(number=1000)
    x = list(range(i))
    pz = popzero.timeit(number=1000)
    print("%15.5f, %15.5f" %(pz,pt))
{% endhighlight %}

<p>На <i>рисунке 3</i> показаны результаты нашего эксперимента. Вы можете видеть, как список делается всё длиннее и длиннее, и время, необходимое для <code>pop(0)</code> тоже увеличивается, тогда как график для <code>pop()</code> остаётся плоским. Это в точности то, что мы ожидали увидеть от алгоритмов с <b><i>O(n)</i></b> и <b><i>O(1)</i></b></p>

<p>Некоторым источником ошибок в нашем маленьком эксперименте стал тот факт, что на компьютере запущены и другие процессы, которые могут замедлять наш код. Несмотря на то, что мы старались минимизировать влияние прочих происходящих на компьютере вещей, с ними связаны некоторые флуктуации времён. Именно поэтому цикл выполняет тест тысячу - в первую очередь, чтобы статистически собрать достаточно информации для утверждения о надёжности измерений.</p>

<p align="center"><img src="http://interactivepython.org/runestone/static/pythonds/_images/poptime.png"></p>
<p align="center">Рисунок 3: Сравнение производительности <code>pop(0)</code> и <code>pop()</code></p>

<h2>Словари</h2>
<p>Второй основной структурой данных в Python является словарь. Как вы, наверное, помните, словари отличаются от списков тем, что в них вы получаете доступ к элементу по ключу, а не по позиции. Позднее в этой книге вы увидите множество способов реализации словаря. Сейчас же наиболее важно отметить, что операции получения и записи элемента в словарь имеют <b><i>O</i>(1)</b>. Другой важной операцией со словарями является определение принадлежности ему элемента. Проверка, есть ли с словаре данный ключ или нет, тоже <b><i>O</i>(1)</b>. Эффективности всех операций над словарями собраны в <i>таблице 3</i>. Важное замечание в сторону относительно производительности словарей: эффективности, которые мы предоставляем в таблице, - это усреднённая производительность. В редких случаях принадлежность, получение или запись элемента могут деградировать до <b><i>O(n)</i></b>. Мы встретимся с этим в одной из последующих глав, когда будем говорить о различных способах, которыми можно реализовать словарь.</p>

<table border="1">
  <caption><b>Таблица 3: Эффективность операций над словарями в Python в терминах нотации "большое О"</b></caption>
  <tr>
    <td>Операция</td><td>Эффективность</td>
  </tr>
  <tr>
    <td>Копирование</td><td>O(n)</td>
  </tr>
  <tr>
    <td>Получить элемент</td><td>O(1)</td>
  </tr>
  <tr>
    <td>Записать элемент</td><td>O(1)</td>
  </tr>
  <tr>
    <td>Удалить элемент</td><td>O(1)</td>
  </tr>
  <tr>
    <td>Принадлежность (in)</td><td>O(1)</td>
  </tr>
  <tr>
    <td>Итерации</td><td>O(n)</td>
  </tr>
</table>

<p>В нашем последнем эксперименте с производительностью мы сравним эффективность операций принадлежности у списков и словарей. В процессе мы подтвердим, что оператор принадлежности для списков имеет <b><i>O(n)</i></b>, а для словарей - <b><i>O</i>(1)</b>. Производить сравнение мы будем просто. Мы создадим список с диапазоном чисел, затем будем брать число случайным образом и смотреть, есть ли оно в списке. Если наша таблица производительности верна, то чем больше список, тем дольше будет происходить определение, содержится ли в нём данное число.</p>

<p>Мы повторим тот же эксперимент со словарём, содержащим числа в качестве ключей. В этом эксперименте мы хотим увидеть, что определение есть или нет число в словаре не только намного быстрее, но и время, занимаемое для проверки, остаётся постоянным, даже если объём словаря возрастает.</p>

<p><i>Листинг 6</i> реализовывает это сравнение. Заметьте, что мы выполняем в точности одинаковые операции <code>number in container</code>. Различие только в том, что в седьмой строке <code>x</code> - это список, а в девятой - словарь.</p>

<b>Листинг 6</b>
{% highlight Python %}
import timeit
import random

for i in range(10000,1000001,20000):
    t = timeit.Timer("random.randrange(%d) in x"%i,
                     "from __main__ import random,x")
    x = list(range(i))
    lst_time = t.timeit(number=1000)
    x = {j:None for j in range(i)}
    d_time = t.timeit(number=1000)
    print("%d,%10.3f,%10.3f" % (i, lst_time, d_time))
{% endhighlight %}

<p><i>Рисунок 4</i> подытоживает результаты запуска <i>Листинга 6</i>. Вы видите, что словарь стабильно быстрее. Для списков малых размеров на 10 000 элементов словарь быстрее в 89,4 раза. Для больших списков на 990 000 элементов разница становится в 11 603 раза! Вы также можете видеть, что время, требуемое операции проверки принадлежности для списка, линейно возрастает с ростом размера списка. Это подтверждает утверждение, что оператор принадлежности для списков имеет <b><i>O(n)</i></b>. Так же хорошо видно, что аналогичная опреация для словаря остаётся постоянной даже при возрастании объёма словаря. Фактически, для словаря размером в 10 000 опреация проверки принадлежности занимает 0,004 миллисекунды, как и для словаря на 990 000 элементов.</p>

<p align="center"><img src="http://interactivepython.org/runestone/static/pythonds/_images/listvdict.png"></p>
<p align="center">Рисунок 4: Сравнение операторов <code>in</code> для списков и словарей в Python</p>

<p>Поскольку Python - развивающийся язык, то за сценой постоянно происходят изменения. Последнюю информацюю о производительности структур данных в Python можно найти на сайте Python. На момент написания этих строк Python wiki имеет хорошую страничку, посвящённую временной сложности. Вы можете ознакомиться с ней <a href="http://wiki.python.org/moin/TimeComplexity">здесь</a>.</p>

<b>Самопроверка</b>
<p>Q-1: Какая из перечисленных операций для списков не является O(1)?</p>
<p>Q-2: Какая из перечисленных операций для словарей не является O(1)?</p>

<h1>Заключение</h1>
<ul>
  <li>Анализ алгоритмов - это независящий от реализации способ оцеки алгоритма.</li>
  <li>Нотация "большое О" позволяет классифицировать алгоритмы по их доминирующим вычислениям относительно размера задачи.</li>
</ul>

<h1>Ключевые термины</h1>
<table>
  <tr>
    <td>ВременнАя сложность </td><td>Квадратичный </td><td>Линейный</td>
  </tr>
  <tr>
    <td>Линейно-логарифмический </td><td>Логарифмический </td><td>Наихудший случай</td>
  </tr>
  <tr>
    <td>Нотация "большое О" </td><td>
Полный перебор </td><td>Порядок величины </td>
  </tr>
  <tr>
    <td>Усреднённый случай </td><td>Установка меток </td><td>
Экспоненциальный </td>
  </tr>
</table>

<h1>Вопросы для обсуждения</h1>
<ol>
  <li>Какова производительность следующего фрагмента кода в терминах нотации "большое О"?
  {% highlight Python %}
  for i in range(n):
   for j in range(n):
      k = 2 + 2
  {% endhighlight %}</li>
  <li>Какова производительность следующего фрагмента кода в терминах нотации "большое О"?
  {% highlight Python %}
   for i in range(n):
     k = 2 + 2
  {% endhighlight %}</li>
  <li>Какова производительность следующего фрагмента кода в терминах нотации "большое О"?
  {% highlight Python %}
    i = n
    while i > 0:
      k = 2 + 2
      i = i // 2
  {% endhighlight %}</li>
  <li>Какова производительность следующего фрагмента кода в терминах нотации "большое О"?
  {% highlight Python %}
    for i in range(n):
      for j in range(n):
        for k in range(n):
          k = 2 + 2
  {% endhighlight %}</li>
  <li>Какова производительность следующего фрагмента кода в терминах нотации "большое О"?
  {% highlight Python %}
   for i in range(n):
     k = 2 + 2
   for j in range(n):
     k = 2 + 2
   for k in range(n):
     k = 2 + 2
  {% endhighlight %}</li>
</ol>

<h1>Упражнения</h1>
<ol>
  <li>Проведите эксперимент, подтверждающий, что оператор индекса для списков имеет <b><i>O</i>(1)</b></li>
  <li>Проведите эксперимент, подтверждающий, что получение и запись элемента в словарь имеют <b><i>O</i>(1)</b></li>
  <li>Проведите эксперимент, сравнивающий производительность оператора <code>del</code> для словарей и списков</li>
  <li>Для заданного списка чисел, расположенных в случайном порядке, напишите работающий за линейное время алгоритм поиска k-го наименьшего элемента. Объясните, почему ваш алгоритм - линейный.</li>
  <li>Можете вы улучшить алгоритм из предыдущего задания, чтобы он был <b><i> O(n</i> log(<i>n</i>))</b>?</li>
</ol>

</body>
</html>
